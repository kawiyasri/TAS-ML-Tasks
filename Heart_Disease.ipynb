{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td0Kk9OO5Ym-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = pd.read_csv('/content/heart (1).csv')\n",
        "dt = dt.drop_duplicates()"
      ],
      "metadata": {
        "id": "8zIFbRv35fmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = len(dt) * 0.2\n",
        "dt = dt.dropna(thresh=len(dt) - threshold, axis=1)"
      ],
      "metadata": {
        "id": "TwDErZv_5r_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in dt.columns:\n",
        "  if dt[col].dtype == 'object':\n",
        "    dt[col] = dt[col].astype('category').cat.codes"
      ],
      "metadata": {
        "id": "C_xBq7yb6OWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm7Vb3Fd6lFT",
        "outputId": "80e8067d-bd3f-479b-e3e9-5961dd00823c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 302 entries, 0 to 878\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       302 non-null    int64  \n",
            " 1   sex       302 non-null    int64  \n",
            " 2   cp        302 non-null    int64  \n",
            " 3   trestbps  302 non-null    int64  \n",
            " 4   chol      302 non-null    int64  \n",
            " 5   fbs       302 non-null    int64  \n",
            " 6   restecg   302 non-null    int64  \n",
            " 7   thalach   302 non-null    int64  \n",
            " 8   exang     302 non-null    int64  \n",
            " 9   oldpeak   302 non-null    float64\n",
            " 10  slope     302 non-null    int64  \n",
            " 11  ca        302 non-null    int64  \n",
            " 12  thal      302 non-null    int64  \n",
            " 13  target    302 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 35.4 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = dt.corr()\n",
        "target_corr = corr_matrix['target']\n",
        "threshold = 0.1\n",
        "features_to_drop = target_corr[abs(target_corr) < threshold].index.tolist()\n",
        "dt = dt.drop(columns=features_to_drop)\n",
        "dt.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ynvR3XL6pUR",
        "outputId": "3e8bfa20-7b9a-44f8-be97-38e30424939f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 302 entries, 0 to 878\n",
            "Data columns (total 12 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       302 non-null    int64  \n",
            " 1   sex       302 non-null    int64  \n",
            " 2   cp        302 non-null    int64  \n",
            " 3   trestbps  302 non-null    int64  \n",
            " 4   restecg   302 non-null    int64  \n",
            " 5   thalach   302 non-null    int64  \n",
            " 6   exang     302 non-null    int64  \n",
            " 7   oldpeak   302 non-null    float64\n",
            " 8   slope     302 non-null    int64  \n",
            " 9   ca        302 non-null    int64  \n",
            " 10  thal      302 non-null    int64  \n",
            " 11  target    302 non-null    int64  \n",
            "dtypes: float64(1), int64(11)\n",
            "memory usage: 30.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "for column in dt.columns:\n",
        "  if dt[column].std() != 0:\n",
        "    print(f\"Column '{column}' might require scaling.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek4mPCAL65Lb",
        "outputId": "13c2d98f-e84f-44df-db9e-b5f36776ecc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'age' might require scaling.\n",
            "Column 'sex' might require scaling.\n",
            "Column 'cp' might require scaling.\n",
            "Column 'trestbps' might require scaling.\n",
            "Column 'restecg' might require scaling.\n",
            "Column 'thalach' might require scaling.\n",
            "Column 'exang' might require scaling.\n",
            "Column 'oldpeak' might require scaling.\n",
            "Column 'slope' might require scaling.\n",
            "Column 'ca' might require scaling.\n",
            "Column 'thal' might require scaling.\n",
            "Column 'target' might require scaling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "X = dt.drop('target', axis=1)\n",
        "y = dt['target']\n",
        "dtorg = dt\n",
        "dt = X\n",
        "for column in dt.columns:\n",
        "  if dt[column].std() != 0:\n",
        "    if dt[column].skew() > 1 or dt[column].skew() < -1:  # Check for skewness (indicating potential outliers)\n",
        "      scaler = RobustScaler()\n",
        "      print(f\"Column '{column}' has outliers, using RobustScaler.\")\n",
        "    elif dt[column].skew() >= -1 and dt[column].skew() <= 1: # Check for normal distribution\n",
        "      scaler = StandardScaler()\n",
        "      print(f\"Column '{column}' is normally distributed, using StandardScaler.\")\n",
        "    else:\n",
        "      scaler = MinMaxScaler()\n",
        "      print(f\"Column '{column}' has a bounded range, using MinMaxScaler.\")\n",
        "    dt[column] = scaler.fit_transform(dt[[column]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3kyQIpa7qiu",
        "outputId": "0935e433-2309-4991-bc18-52dc48151632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'age' is normally distributed, using StandardScaler.\n",
            "Column 'sex' is normally distributed, using StandardScaler.\n",
            "Column 'cp' is normally distributed, using StandardScaler.\n",
            "Column 'trestbps' is normally distributed, using StandardScaler.\n",
            "Column 'restecg' is normally distributed, using StandardScaler.\n",
            "Column 'thalach' is normally distributed, using StandardScaler.\n",
            "Column 'exang' is normally distributed, using StandardScaler.\n",
            "Column 'oldpeak' has outliers, using RobustScaler.\n",
            "Column 'slope' is normally distributed, using StandardScaler.\n",
            "Column 'ca' has outliers, using RobustScaler.\n",
            "Column 'thal' is normally distributed, using StandardScaler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Check for PCA applicability (if dataset has many features and some are highly correlated)\n",
        "if X.shape[1] > 10 and np.linalg.matrix_rank(X.corr()) < X.shape[1]:\n",
        "    print(\"PCA might be beneficial for dimensionality reduction.\")\n",
        "\n",
        "    # Determine the optimal number of components for PCA using explained variance ratio\n",
        "    pca = PCA()\n",
        "    pca.fit(X_train)\n",
        "    explained_variance_ratio = pca.explained_variance_ratio_\n",
        "    cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "    # Choose the number of components that explain at least 95% of the variance\n",
        "    n_components = np.argmax(cumulative_variance_ratio >= 0.95) + 1\n",
        "\n",
        "    print(f\"Optimal number of PCA components: {n_components}\")\n",
        "\n",
        "    # Apply PCA\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_train_pca = pca.fit_transform(X_train)\n",
        "    X_test_pca = pca.transform(X_test)\n",
        "\n",
        "    # Replace original features with PCA components\n",
        "    X_train = pd.DataFrame(X_train_pca)\n",
        "    X_test = pd.DataFrame(X_test_pca)\n",
        "\n",
        "# Check for LDA applicability (if dataset has a clear class separation)\n",
        "elif len(y.unique()) > 1 and y.value_counts().min() > 10:\n",
        "    print(\"LDA might be beneficial for dimensionality reduction and feature extraction.\")\n",
        "    lda = LDA(n_components=min(len(y.unique()) - 1, X.shape[1]))\n",
        "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
        "    X_test_lda = lda.transform(X_test)\n",
        "\n",
        "    # Replace original features with LDA components\n",
        "    X_train = pd.DataFrame(X_train_lda)\n",
        "    X_test = pd.DataFrame(X_test_lda)\n",
        "\n",
        "else:\n",
        "  print(\"PCA or LDA is not necessary or not applicable based on the current data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS2YiLDu8gwO",
        "outputId": "8453428e-c1a4-4853-bd0c-575ae7fb6f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA might be beneficial for dimensionality reduction and feature extraction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Choose a classification algorithm based on the nature of your problem\n",
        "# and data characteristics.\n",
        "\n",
        "# 1. Logistic Regression: A good baseline for binary classification.\n",
        "#    Suitable for linearly separable data or when interpretability is desired.\n",
        "# 2. Decision Tree: Useful for handling non-linear relationships and interactions.\n",
        "#    Can be prone to overfitting if not properly pruned or controlled.\n",
        "# 3. Random Forest: An ensemble method combining multiple decision trees.\n",
        "#    Robust to overfitting and generally provides high accuracy.\n",
        "# 4. Support Vector Machine (SVM): Powerful for complex datasets with clear margins.\n",
        "#    Can be computationally expensive and sensitive to hyperparameter tuning.\n",
        "# 5. K-Nearest Neighbors (KNN): Based on the similarity of data points.\n",
        "#    Simple to implement but can be computationally expensive for large datasets.\n",
        "# 6. Naive Bayes: Assumes independence between features, suitable for text classification.\n",
        "#    Can be less accurate than other algorithms for complex relationships.\n",
        "\n",
        "# Example of choosing a classifier and evaluating its performance:\n",
        "# We'll select Random Forest as a starting point.\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{report}\")\n",
        "\n",
        "# You can experiment with different classifiers and compare their performance\n",
        "# to choose the most suitable one for your data and problem.\n",
        "\n",
        "# Example of comparing multiple classifiers:\n",
        "classifiers = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name}: Accuracy = {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVgENaoi9OyQ",
        "outputId": "726c3ecf-b37b-4bca-b81b-23a556837240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6885245901639344\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.69      0.70        32\n",
            "           1       0.67      0.69      0.68        29\n",
            "\n",
            "    accuracy                           0.69        61\n",
            "   macro avg       0.69      0.69      0.69        61\n",
            "weighted avg       0.69      0.69      0.69        61\n",
            "\n",
            "Logistic Regression: Accuracy = 0.819672131147541\n",
            "Decision Tree: Accuracy = 0.6885245901639344\n",
            "Random Forest: Accuracy = 0.6885245901639344\n",
            "SVM: Accuracy = 0.8360655737704918\n",
            "KNN: Accuracy = 0.7868852459016393\n",
            "Naive Bayes: Accuracy = 0.8032786885245902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are already defined\n",
        "\n",
        "# Create a dictionary of classifiers\n",
        "classifiers = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "results = {}\n",
        "for name, clf in classifiers.items():\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  results[name] = accuracy\n",
        "\n",
        "# Find the best classifier based on accuracy\n",
        "best_classifier = max(results, key=results.get)\n",
        "best_accuracy = results[best_classifier]\n",
        "\n",
        "# Print the best classifier and its accuracy\n",
        "print(f\"The best classifier is: {best_classifier}\")\n",
        "print(f\"With accuracy: {best_accuracy}\")\n",
        "\n",
        "# Now you can use the best_classifier for your predictions\n",
        "best_clf = classifiers[best_classifier]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRfq7c_P-E0g",
        "outputId": "c5b90bd3-b08f-41c6-a353-7692b2c5dd0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best classifier is: SVM\n",
            "With accuracy: 0.8360655737704918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance:\n",
        "import pandas as pd\n",
        "if isinstance(best_clf, RandomForestClassifier):\n",
        "  # Feature Importance for Random Forest\n",
        "  importances = best_clf.feature_importances_\n",
        "  feature_importances = pd.DataFrame({'feature': X_train.columns, 'importance': importances})\n",
        "  feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
        "  print(\"Feature Importance (Random Forest):\")\n",
        "  print(feature_importances)\n",
        "elif isinstance(best_clf, LogisticRegression):\n",
        "  # Feature Importance for Logistic Regression (coefficients)\n",
        "  coefficients = best_clf.coef_[0]\n",
        "  feature_importances = pd.DataFrame({'feature': X_train.columns, 'importance': coefficients})\n",
        "  feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
        "  print(\"Feature Importance (Logistic Regression - Coefficients):\")\n",
        "  print(feature_importances)\n",
        "elif isinstance(best_clf, DecisionTreeClassifier):\n",
        "  # Feature Importance for Decision Tree\n",
        "  importances = best_clf.feature_importances_\n",
        "  feature_importances = pd.DataFrame({'feature': X_train.columns, 'importance': importances})\n",
        "  feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
        "  print(\"Feature Importance (Decision Tree):\")\n",
        "  print(feature_importances)\n",
        "else:\n",
        "  print(\"Feature importance is not readily available for this classifier.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfntKBWR-toj",
        "outputId": "4de414c5-68f9-4493-8196-e2b8bed59ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importance is not readily available for this classifier.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Check if the best classifier is a tree-based model (DecisionTree or RandomForest)\n",
        "if isinstance(best_clf, (DecisionTreeClassifier, RandomForestClassifier)):\n",
        "    # Define the parameter grid to search\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "elif isinstance(best_clf, SVC):\n",
        "    # Define a parameter grid suitable for SVC\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    }\n",
        "# Add other elif blocks for other classifier types if needed with appropriate parameters\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=best_clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best accuracy found: \", grid_search.best_score_)\n",
        "\n",
        "# Use the best estimator for predictions\n",
        "best_clf = grid_search.best_estimator_\n",
        "y_pred = best_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with tuned model: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBHV97lU_bhb",
        "outputId": "dfd30b3f-13ad-478c-9da7-1131783b5c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "Best accuracy found:  0.8713435374149661\n",
            "Accuracy with tuned model: 0.8360655737704918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whl14YeN_tWQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}